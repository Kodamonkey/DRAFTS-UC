<h1 align='center'> DRAFTS </h1>

<div align="center">

‚ú® **Deep learning-based RAdio Fast Transient Search pipeline** ‚ú®

[![TransientSearch](https://img.shields.io/badge/TransientSearch-DRAFTS-da282a)](https://github.com/SukiYume/DRAFTS)
[![GitHub Stars](https://img.shields.io/github/stars/SukiYume/DRAFTS.svg?label=Stars&logo=github)](https://github.com/SukiYume/DRAFTS/stargazers)
[![arXiv](https://img.shields.io/badge/arXiv-2410.03200-b31b1b.svg)](https://arxiv.org/abs/2410.03200)
[![Python](https://img.shields.io/badge/Python-3.6+-blue.svg)](https://www.python.org/)

[Description](#description) ‚Ä¢
[Installation](#installation) ‚Ä¢
[Usage](#usage) ‚Ä¢
[Models](#models) ‚Ä¢
[Performance](#performance) ‚Ä¢
[Real Data Search](#search-in-real-observation-data) ‚Ä¢
[Contributing](#contributing)

</div>

![DRAFTS WorkFlow](./WorkFlow.png)

## Description

**DRAFTS** is a Deep learning-based RAdio Fast Transient Search pipeline designed to address limitations in traditional single-pulse search techniques like Presto and Heimdall.

Traditional methods often face challenges including:

- Complex installation procedures
- Slow execution speeds
- Incomplete search results
- Heavy reliance on manual verification

Our pipeline offers three key components:

1. **CUDA-accelerated de-dispersion** for faster processing
2. **Object detection model** to extract Time of Arrival (TOA) and Dispersion Measure (DM) of FRB signals
3. **Binary classification model** to verify candidate signal authenticity

**Key advantages:**

- Written entirely in Python for easy cross-platform installation
- Achieves real-time searching on consumer GPUs (tested on RTX 2070S)
- Nearly doubles burst detection compared to Heimdall
- Classification accuracy exceeding 99% on FAST and GBT data
- Significantly reduces manual verification requirements

üìÑ **Publication:** [DRAFTS: A Deep Learning-Based Radio Fast Transient Search Pipeline (arXiv:2410.03200)](https://arxiv.org/abs/2410.03200)

## New Features

### üÜï Sistema Autom√°tico de Par√°metros

**¬°Configuraci√≥n simplificada!** Ahora solo necesitas configurar `SLICE_DURATION_MS` en `user_config.py` y el sistema calcula autom√°ticamente todos los dem√°s par√°metros optimizados.

#### üöÄ Uso B√°sico

```python
# En user_config.py - Solo esto:
SLICE_DURATION_MS: float = 64.0  # Duraci√≥n deseada de cada slice en ms

# Ejecuci√≥n:
python main.py  # Modo autom√°tico por defecto
```

#### ‚ú® Caracter√≠sticas

- **C√°lculo autom√°tico** de `chunk_samples` optimizado para memoria
- **Optimizaci√≥n inteligente** basada en hardware disponible
- **Validaci√≥n autom√°tica** de todos los par√°metros
- **Logs informativos** del proceso de c√°lculo
- **Compatibilidad total** con el sistema existente

#### üìä Configuraciones T√≠picas

| Caso de Uso     | SLICE_DURATION_MS | Descripci√≥n                               |
| --------------- | ----------------- | ----------------------------------------- |
| FRB r√°pidos     | 32.0 ms           | Slices cortos para pulsos muy r√°pidos     |
| FRB general     | 64.0 ms           | Balance entre sensibilidad y velocidad    |
| Pulsos largos   | 128.0 ms          | Slices m√°s largos para pulsos extendidos  |
| Se√±ales d√©biles | 256.0 ms          | Mayor integraci√≥n temporal para mejor SNR |

üìñ **Documentaci√≥n completa**: [Sistema Autom√°tico de Par√°metros](docs/SISTEMA_AUTOMATICO.md)

### üÜï Optimizaci√≥n de Carpetas

**¬°Organizaci√≥n inteligente!** El sistema ahora solo crea carpetas cuando realmente hay contenido para guardar, evitando carpetas vac√≠as y mejorando la eficiencia.

#### üóÇÔ∏è Caracter√≠sticas

- **Carpetas inteligentes**: Solo se crean cuando hay candidatos
- **Ahorro de espacio**: Eliminaci√≥n de carpetas vac√≠as
- **Mejor navegaci√≥n**: Encontrar resultados m√°s f√°cilmente
- **Rendimiento optimizado**: Menos operaciones de I/O

#### üìÅ Tipos Optimizados

| Carpeta                   | Comportamiento          |
| ------------------------- | ----------------------- |
| `Composite/`              | Solo si hay candidatos  |
| `Detections/`             | Solo si hay detecciones |
| `Patches/`                | Solo si hay patches     |
| `waterfall_dispersion/`   | Solo si hay datos       |
| `waterfall_dedispersion/` | Solo si hay candidatos  |

### üÜï Signal-to-Noise Ratio (SNR) Analysis

The pipeline now includes comprehensive SNR analysis capabilities that enhance the detection and visualization of FRB candidates:

#### Key Features

- **Automatic SNR Calculation**: All candidate patches now display temporal profiles in SNR units (œÉ) instead of raw intensity
- **Robust Noise Estimation**: Uses Interquartile Range (IQR) method for noise estimation, robust to multiple pulses
- **Configurable Thresholds**: Set `SNR_THRESH` in `config.py` to highlight significant detections
- **Enhanced Visualizations**:
  - SNR profiles with peak annotations
  - Threshold lines for detection significance
  - Color-coded regions above threshold
  - Vertical markers showing peak positions

#### Configuration Parameters

Add these to your `config.py`:

```python
# SNR and Visualization Configuration
SNR_THRESH = 5.0  # Threshold for highlighting detections
SNR_OFF_REGIONS = [(-200, -100), (-50, 50), (100, 200)]  # Off-pulse regions
SNR_COLORMAP = "viridis"  # Colormap for waterfalls
SNR_HIGHLIGHT_COLOR = "red"  # Color for threshold highlighting
```

#### New Functions Available

- **`compute_snr_profile()`**: Calculate SNR profile from waterfall data
- **`find_snr_peak()`**: Locate and quantify peak SNR values
- **`inject_synthetic_frb()`**: Generate synthetic FRBs for testing
- **`estimate_sigma_iqr()`**: Robust noise estimation
- **`compute_detection_significance()`**: Statistical significance calculation

#### Enhanced Outputs

The pipeline now generates:

1. **SNR-enhanced patch plots** with annotated peaks and thresholds
2. **Composite summary plots** showing three SNR profiles:
   - Raw waterfall SNR (blue)
   - Dedispersed waterfall SNR (green)
   - Candidate patch SNR (orange)
3. **Peak markers** on all waterfall displays
4. **Significance annotations** with œÉ values

#### Testing

Run the SNR integration test:

```bash
python test_snr_integration.py
```

This creates test outputs in `test_snr_output/` to verify SNR functionality.

#### Scientific Benefits

- **Quantitative Assessment**: All detections now have quantitative SNR measurements
- **Improved Filtering**: Easy identification of high-significance candidates
- **Statistical Analysis**: Built-in significance calculation considering multiple trials
- **Robust Processing**: IQR-based noise estimation handles challenging noise environments

## Installation

Install all required dependencies from the `requirements.txt` file in the
repository root with:

```bash
pip install -r requirements.txt
```

## Usage

Training data and pre-trained models are available on HuggingFace:

- [DRAFTS-Data](https://huggingface.co/datasets/TorchLight/DRAFTS)
- [DRAFTS-Model](https://huggingface.co/TorchLight/DRAFTS)

### Pipeline Steps

1. **Preprocessing** ‚Äì Edit configuration variables such as `DM_range`,
   `block_size`, `data_path` and `save_path` in `d-center-main.py` or
   `d-resnet-main.py`. These scripts load FITS files and perform GPU-accelerated
   de-dispersion.
2. **Object detection** ‚Äì Run `d-center-main.py` with a trained CenterNet model.
   Detected candidates are saved as images with bounding boxes and optional
   `.npy` arrays for subsequent analysis.
3. **Binary classification** ‚Äì Execute `d-resnet-main.py` with the classification
   model path configured. The script outputs probability scores for each
   candidate and stores cropped bursts in the specified save directory.
4. **Visualization** ‚Äì When plotting waterfalls with `plot_waterfall_block`,
   set `normalize=True` to scale each frequency channel to unit mean and clip
   between the 5th and 95th percentiles for clear images across varying
   `SLICE_LEN` and DM ranges.

### Models

#### Object Detection

The object detection training code is in the `ObjectDet` folder.

1. Download data to `ObjectDet/Data`
2. Place `data_label.txt` in the same directory as `centernet_train.py`
3. Train using:

```bash
python centernet_train.py resnet18  # Use 'resnet50' for ResNet50 backbone
```

#### Binary Classification

The classification training code is in the `BinaryClass` folder.

1. Download data to `BinaryClass/Data`
2. Ensure data is organized in `True` and `False` subfolders
3. Train standard model:

```bash
python binary_train.py resnet18 BinaryNet  # Use 'resnet50' for ResNet50 backbone
```

4. Train with arbitrary image size support using `SpatialPyramidPool2D`:

```bash
python binary_train.py resnet18 SPPResNet
```

### Performance

To evaluate model performance:

1. Use the [FAST-FREX](https://doi.org/10.57760/sciencedb.15070) independent dataset
2. Place FITS files in `CheckRes/RawData/Data`
3. Place trained model checkpoints in the same directory as the Python files
4. Run evaluation scripts:
   - Files with `ddmt` for classification models
   - Files with `cent` for object detection models

**Dependencies:**

- Classification models depend on `binary_model.py`
- Object detection models depend on `centernet_utils.py` and `centernet_model.py`

## Search in Real Observation Data

For complete FAST observation data:

1. Refer to `d-center-main.py` and `d-resnet-main.py`
2. Modify the `data path` and `save path`
3. Set `FRB_TARGETS` in `effelsberg/config.py` to match the FRB names in your FITS files
4. Run the file

**Note:** The current search program automatically adapts to FAST and GBT observation data. For other telescopes, modify the `load_fits_file` function and related data reading functions.

## Contributing

Contributions to DRAFTS are welcome! Please feel free to submit issues or pull requests.

---

<div align="center">
  <sub>Searching for cosmic signals üî≠‚ú®üì°</sub>
</div># DRAFTS-FE
