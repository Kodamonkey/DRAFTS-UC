# Docker Compose for DRAFTS-UC

# ==============================================================================
# DRAFTS-UC Pipeline - Docker Compose
# ==============================================================================
# This file defines services to run the pipeline on CPU or GPU
#
# IMPORTANT: Configure the pipeline by editing config.yaml before running
#
# Usage:
#   - CPU:  docker-compose run --rm drafts-cpu
#   - GPU:  docker-compose run --rm drafts-gpu
#
# Build:
#   - CPU:  docker-compose build drafts-cpu
#   - GPU:  docker-compose build drafts-gpu
#
# The pipeline reads configuration from config.yaml (mounted as volume)
# ==============================================================================

services:
  # ============================================================================
  # CPU Service - For systems without NVIDIA GPU
  # ============================================================================
  drafts-cpu:
    build:
      context: .
      dockerfile: Dockerfile
      target: cpu-final
    image: drafts-uc:cpu-latest
    container_name: drafts-uc-cpu
    
    # Volumes for data, results, models and configuration
    volumes:
      # Pipeline configuration (REQUIRED - read-write for updates)
      - ./config.yaml:/app/config.yaml:rw
      
      # Input data (read-only recommended)
      #- ./Data/raw:/app/Data/raw:ro
      - D:/Seba - Dev/TESIS/Data/raw/No0153/0006:/app/Data/raw:ro
      
      # Results (read-write)
      - ./Results:/app/Results:rw
      
      # Pre-trained models (read-only) - where code looks for them
      - ./src/models:/app/src/models:ro
      
      # Optional: persistent logs
      # - ./logs:/app/logs:rw
      
      # Optional: temporary processed data
      # - ./Data/processed:/app/Data/processed:rw
    
    # Environment variables
    environment:
      - PYTHONUNBUFFERED=1
      - OMP_NUM_THREADS=4
      - MKL_NUM_THREADS=4
      - NUMBA_NUM_THREADS=4
    
    # Resource limits
    deploy:
      resources:
        limits:
          cpus: '8'
          memory: 16G
        reservations:
          cpus: '4'
          memory: 8G
    
    # Network
    network_mode: bridge
    
    # Restart policy
    restart: "no"
    
    # User
    user: "1000:1000"

  # ============================================================================
  # GPU Service - For systems with NVIDIA GPU + CUDA
  # ============================================================================
  drafts-gpu:
    build:
      context: .
      dockerfile: Dockerfile
      target: gpu-final
    image: drafts-uc:gpu-latest
    container_name: drafts-uc-gpu
    
    # NVIDIA runtime for GPU access
    runtime: nvidia
    
    # Volumes for data, results, models and configuration
    volumes:
      # Pipeline configuration (REQUIRED - read-write for updates)
      - ./config.yaml:/app/config.yaml:rw
      
      # Input data (read-only recommended)
      # Change this path to your actual data location
      - D:/Seba - Dev/TESIS/Data/raw/No0153/0006:/app/Data/raw:ro
      
      # Results (read-write)
      - ./Results:/app/Results:rw
      
      # Pre-trained models (read-only) - where code looks for them
      - ./src/models:/app/src/models:ro
      
      # Optional: persistent logs
      # - ./logs:/app/logs:rw
      
      # Optional: temporary processed data
      # - ./Data/processed:/app/Data/processed:rw
    
    # Environment variables for GPU
    environment:
      - PYTHONUNBUFFERED=1
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      - CUDA_VISIBLE_DEVICES=0
    
    # Resource limits
    deploy:
      resources:
        limits:
          cpus: '8'
          memory: 32G
        reservations:
          cpus: '4'
          memory: 16G
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    
    # Network
    network_mode: bridge
    
    # Restart policy
    restart: "no"
    
    # User
    user: "1000:1000"

# ==============================================================================
# Named volumes (optional)
# ==============================================================================
# Uncomment if you prefer using named volumes instead of bind mounts
# volumes:
#   drafts-data:
#     driver: local
#   drafts-results:
#     driver: local
#   drafts-models:
#     driver: local

